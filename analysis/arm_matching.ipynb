{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomo-for-lab/Code-of-automating-DE/blob/main/analysis/arm_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoyXjQrY101L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09c4c59-91fc-4365-bdd2-3eae7890dc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai weave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7jxquilthnH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ipykernel\n",
        "from notebook.notebookapp import list_running_servers\n",
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "import json\n",
        "import os\n",
        "from google.colab import auth\n",
        "from google.colab import userdata\n",
        "from googleapiclient.discovery import build\n",
        "import glob\n",
        "\n",
        "from openai import OpenAI\n",
        "from openai import AzureOpenAI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the working directory to the path of the current notebook"
      ],
      "metadata": {
        "id": "OI0DpEd3_6rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8mwIHFzdEk8",
        "outputId": "21d5b9a9-529b-4240-cb61-a3a42cdfc94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# Mount Google Drive to access files stored in it\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "def get_notebook_path():\n",
        "    # Get the path of the current Jupyter notebook\n",
        "    kernel_id = re.search('kernel-(.*).json', ipykernel.get_connection_file()).group(1)\n",
        "    servers = list_running_servers()\n",
        "    for ss in servers:\n",
        "        response = requests.get(urljoin(ss['url'], 'api/sessions'), params={'token': ss.get('token', '')})\n",
        "        for nn in json.loads(response.text):\n",
        "            if nn['kernel']['id'] == kernel_id:\n",
        "                relative_path = nn['notebook']['path']\n",
        "                return os.path.join(ss['notebook_dir'], relative_path)\n",
        "\n",
        "def get_folder_path(folder_id):\n",
        "    # Recursively get the full path of a folder given its ID\n",
        "    if folder_id:\n",
        "        folder = drive_service.files().get(fileId=folder_id, fields=\"name, parents\").execute()\n",
        "        folder_name = folder.get('name')\n",
        "        parents = folder.get('parents')\n",
        "        if parents:\n",
        "            parent_path = get_folder_path(parents[0])\n",
        "            return parent_path + '/' + folder_name\n",
        "        else:\n",
        "            return folder_name\n",
        "    return ''\n",
        "\n",
        "def get_file_path(file_id):\n",
        "    # Recursively get the full path of a file given its ID\n",
        "    file = drive_service.files().get(fileId=file_id, fields=\"name, parents\").execute()\n",
        "    file_name = file.get('name')\n",
        "    parents = file.get('parents')\n",
        "    if parents:\n",
        "        parent_id = parents[0]\n",
        "        parent_path = get_folder_path(parent_id)\n",
        "        return parent_path\n",
        "    else:\n",
        "        return file_name\n",
        "\n",
        "# Get the path of the current notebook\n",
        "notebook_path = get_notebook_path()\n",
        "\n",
        "\n",
        "# Authenticate and initialize the Google Drive API\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Extract the file ID from the notebook path (assumes file ID is part of the path)\n",
        "file_id = re.search(r'fileId=(\\w+)', notebook_path).group(1)\n",
        "\n",
        "# Get the full path of the file using its ID\n",
        "file_path = get_file_path(file_id)\n",
        "if 'ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–' in file_path:\n",
        "    converted_path = re.sub(r'(^|/)ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–($|/)', '/content/drive/MyDrive/', file_path)\n",
        "elif 'MyDrive' in file_path:\n",
        "    converted_path = re.sub(r'(^|/)MyDrive($|/)', '/content/drive/MyDrive/', file_path)\n",
        "else:\n",
        "    converted_path = '/content/drive/MyDrive/' + file_path\n",
        "\n",
        "# Change the working directory to the converted path\n",
        "os.chdir(converted_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmc-7Zl3rnDR"
      },
      "outputs": [],
      "source": [
        "import weave"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QxsJC0gFvhy"
      },
      "source": [
        "# Preparation of Azure for GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV637DAVGbcB"
      },
      "outputs": [],
      "source": [
        "#deploy names\n",
        "deployment_ids = [\"gpt-4o\",\"gpt-4-turbo\",\"gpt-3.5-turbo\",\"text-embedding-ada-002\"]\n",
        "\n",
        "#If you use Azure\n",
        "#key\n",
        "API_KEY = userdata.get('Azure_API_key')\n",
        "RESOURCE_ENDPOINT = userdata.get('RESOURCE_ENDPOINT')\n",
        "AZURE_API_version = userdata.get('AZURE_API_version')\n",
        "\n",
        "#client\n",
        "client = AzureOpenAI(\n",
        "    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
        "    api_version=AZURE_API_version,\n",
        "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
        "    azure_endpoint=RESOURCE_ENDPOINT,\n",
        "    api_key=API_KEY\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu8gmdiVLuXo"
      },
      "source": [
        "#Create a dict of human-extracted arm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teTsIJUB1w8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b50f871-d9c8-413f-cb19-b664d4bd6eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "295\n"
          ]
        }
      ],
      "source": [
        "# Specify the file path and sheet name for the Excel file\n",
        "file_path = 'DE.xlsx'\n",
        "sheet_name = 'R1_FINAL'\n",
        "\n",
        "# Read the Excel file, specifying header=1 because the first row is blank\n",
        "df = pd.read_excel(file_path, sheet_name=sheet_name, header=1)\n",
        "\n",
        "# Initialize a dictionary to store the results\n",
        "study_dict = {}\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    study_name = row['study'] # Get the study name from the 'study' column\n",
        "    arm_name = row['Arm'] # Get the arm name from the 'Arm' column\n",
        "    if pd.notna(study_name):\n",
        "        if study_name not in study_dict:\n",
        "            study_dict[study_name] = []\n",
        "        # Append the arm name to the list corresponding to the study name\n",
        "        study_dict[study_name].append(arm_name)\n",
        "\n",
        "print(len(study_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-3ujZG7rcqH"
      },
      "source": [
        "# Define required function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to create tools for matching names of arms extracted by GPT and human"
      ],
      "metadata": {
        "id": "5HVs98ecLPMO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB-p9uApGMxG"
      },
      "outputs": [],
      "source": [
        "def make_tools(GPT_arms_list):\n",
        "  tools_properties = {}\n",
        "\n",
        "  # Iterate over the list of arm names and add them to the tools_properties dictionary\n",
        "  for arm_name in GPT_arms_list:\n",
        "    tools_properties[arm_name] = {'type': 'string', 'description': 'Answer the matched word.'} # Provide a description for the property\n",
        "\n",
        "  tools = [{'type': 'function',\n",
        "      'function':\n",
        "          {'name': 'word_matching',\n",
        "          'description': 'Answer the word matched to the name',\n",
        "          'parameters': {\n",
        "              'type': 'object',\n",
        "            'properties': tools_properties\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "  ]\n",
        "\n",
        "  tools[0]['function']['parameters']['required'] = GPT_arms_list\n",
        "  return tools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for GPT function calling"
      ],
      "metadata": {
        "id": "Gp5E1gsKNDEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yZOyHEaZSKT"
      },
      "outputs": [],
      "source": [
        "@weave.op() # ğŸ\n",
        "def GPT_function_calling(tools, messages, tools_name):\n",
        "  response = client.chat.completions.create(\n",
        "        model=deployment_ids[0],\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice =  {\"type\": \"function\", \"function\": {\"name\": tools_name}},\n",
        "        temperature=0\n",
        "    )\n",
        "  return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhj80A3uQjXj"
      },
      "source": [
        "#Match arm name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am_Ewh8YQjXk"
      },
      "outputs": [],
      "source": [
        "# Create initial DataFrame\n",
        "columns = [\"n_index\", \"fold_index\", \"eval_index\", \"paper_name\", \"GPT_1\", \"GPT_2\", \"GPT_3\", \"GPT_4\", \"GPT_5\",\n",
        "           \"human_1\", \"human_2\", \"human_3\", \"human_4\", \"human_5\", \"key_1\", \"key_1_matched\", \"value_1\", \"value_1_matched\",\n",
        "           \"key_2\", \"key_2_matched\", \"value_2\", \"value_2_matched\", \"key_3\", \"key_3_matched\", \"value_3\", \"value_3_matched\",\n",
        "           \"key_4\", \"key_4_matched\", \"value_4\", \"value_4_matched\", \"key_5\", \"key_5_matched\", \"value_5\", \"value_5_matched\", \"error\"]\n",
        "df_output = pd.DataFrame(columns=columns)\n",
        "df_output.loc[0] = {col: \"\" for col in columns}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9412254b-2f70-42b4-b32d-b8b99d8807af",
        "id": "dsLCxuj9QjXk"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "weave.init(\"arm_matching_GPT4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975c7e76-154f-48b0-cc7b-e5439724a3a2",
        "id": "a6a9fEuFQjXl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_index:  5\n",
            "fold_index:  0\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/5420b846-a6f0-4ff0-aa0d-06822805e065\n",
            "n_index:  5\n",
            "fold_index:  0\n",
            "eval_index:  1\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/097e1e1a-2f8d-4e87-91b9-d7aa9456cbba\n",
            "n_index:  5\n",
            "fold_index:  0\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/a742951d-1fb3-4649-a4b8-477515a2b507\n",
            "n_index:  5\n",
            "fold_index:  0\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/91ac790f-873a-4137-882b-40ed558b1366\n",
            "n_index:  5\n",
            "fold_index:  0\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/c6f52fcb-aaef-45ed-ab73-92cb475d8602\n",
            "n_index:  5\n",
            "fold_index:  1\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/87ae2aeb-a79d-45e2-9e26-6c7796078558\n",
            "n_index:  5\n",
            "fold_index:  1\n",
            "eval_index:  1\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/f3d70020-e563-490b-b503-f5814c0ef0fe\n",
            "n_index:  5\n",
            "fold_index:  1\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/659f9e81-fd57-4655-a145-04a11e94f94f\n",
            "n_index:  5\n",
            "fold_index:  1\n",
            "eval_index:  3\n",
            "error_type:  no_paper_name\n",
            "n_index:  5\n",
            "fold_index:  1\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/39bba93a-8fd8-44b2-912f-328881048d89\n",
            "n_index:  5\n",
            "fold_index:  2\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/97be5f1a-4296-4aec-b117-a238d29e1b3f\n",
            "n_index:  5\n",
            "fold_index:  2\n",
            "eval_index:  1\n",
            "error_type:  no_paper_name\n",
            "n_index:  5\n",
            "fold_index:  2\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/5d177e4f-d43f-4fe6-9e52-f8039554337e\n",
            "n_index:  5\n",
            "fold_index:  2\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/2a9a577a-d942-4f38-baae-f18865080fbe\n",
            "n_index:  5\n",
            "fold_index:  2\n",
            "eval_index:  4\n",
            "error_type:  number_of_arms\n",
            "n_index:  5\n",
            "fold_index:  3\n",
            "eval_index:  0\n",
            "error_type:  extracted_data_loading\n",
            "n_index:  5\n",
            "fold_index:  3\n",
            "eval_index:  1\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/59ef1cb8-4a0a-4531-8cfd-0a0f0962fa43\n",
            "n_index:  5\n",
            "fold_index:  3\n",
            "eval_index:  2\n",
            "error_type:  number_of_arms\n",
            "n_index:  5\n",
            "fold_index:  3\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/8d34375f-dd91-4736-ba1b-e9b062755884\n",
            "n_index:  5\n",
            "fold_index:  3\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/ada143f5-dd65-4d74-958a-3fab3dff86fe\n",
            "n_index:  5\n",
            "fold_index:  4\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/6807dc1a-7553-4b8b-b5ef-ec4bbda6a294\n",
            "n_index:  5\n",
            "fold_index:  4\n",
            "eval_index:  1\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/404d54a2-3615-45e8-a8a3-8ec9e03aa96d\n",
            "n_index:  5\n",
            "fold_index:  4\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/fc6e1319-290f-421f-b551-2fa960d040b0\n",
            "n_index:  5\n",
            "fold_index:  4\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/38778670-639c-4506-b873-6f957e28b806\n",
            "n_index:  5\n",
            "fold_index:  4\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/fa95fd6c-d892-4ddd-9fb8-614115cb4130\n",
            "n_index:  5\n",
            "fold_index:  5\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/f0e9cf3c-1bc5-41ea-8e63-3fe184f714e5\n",
            "n_index:  5\n",
            "fold_index:  5\n",
            "eval_index:  1\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/4503b9e5-899a-4c11-8502-421da84a1212\n",
            "n_index:  5\n",
            "fold_index:  5\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/f07b1f82-56b4-4a4b-95ca-617f918fffba\n",
            "n_index:  5\n",
            "fold_index:  5\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/0076dd64-a7bb-4ae6-99a3-eda63d9c1088\n",
            "n_index:  5\n",
            "fold_index:  5\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/d706ca54-c507-4a2d-b63c-ad99635ae93b\n",
            "n_index:  5\n",
            "fold_index:  6\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/12f8611c-0e43-4966-994d-38e8ff873b76\n",
            "n_index:  5\n",
            "fold_index:  6\n",
            "eval_index:  1\n",
            "error_type:  number_of_arms\n",
            "n_index:  5\n",
            "fold_index:  6\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/a9ee4347-c34e-4704-947e-925204857724\n",
            "n_index:  5\n",
            "fold_index:  6\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/152b2cfd-03f5-4abe-8e5d-4cb8d7781c61\n",
            "n_index:  5\n",
            "fold_index:  6\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/bb177355-886e-4f6f-a268-0208f9e0cdc2\n",
            "n_index:  5\n",
            "fold_index:  7\n",
            "eval_index:  0\n",
            "error_type:  no_paper_name\n",
            "n_index:  5\n",
            "fold_index:  7\n",
            "eval_index:  1\n",
            "error_type:  extracted_data_loading\n",
            "n_index:  5\n",
            "fold_index:  7\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/63daa973-335e-48fd-ad77-adcbe9d3ccd2\n",
            "n_index:  5\n",
            "fold_index:  7\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/9298fd45-50fe-47c7-a6de-fc8caaa002cd\n",
            "n_index:  5\n",
            "fold_index:  7\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/44c6c6cc-af76-4ee9-8ebc-debf430a44ae\n",
            "n_index:  5\n",
            "fold_index:  8\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/866a6f53-3961-4ab1-9d6d-68f670d888bd\n",
            "n_index:  5\n",
            "fold_index:  8\n",
            "eval_index:  1\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/12742dff-2773-4051-9c71-b912d53ea0c0\n",
            "n_index:  5\n",
            "fold_index:  8\n",
            "eval_index:  2\n",
            "error_type:  number_of_arms\n",
            "n_index:  5\n",
            "fold_index:  8\n",
            "eval_index:  3\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/2649541c-eb89-4969-9ba0-86f5e5ca62c5\n",
            "n_index:  5\n",
            "fold_index:  8\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/fe4b42c8-87b2-4c69-86c3-57779c583dd2\n",
            "n_index:  5\n",
            "fold_index:  9\n",
            "eval_index:  0\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/91a3ad9a-be63-4f0e-b131-66082a655fd3\n",
            "n_index:  5\n",
            "fold_index:  9\n",
            "eval_index:  1\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/fe2211f0-9afe-41df-8bbd-bb6ffd51d143\n",
            "n_index:  5\n",
            "fold_index:  9\n",
            "eval_index:  2\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/1a870745-8143-491a-af76-6043c9fdc2db\n",
            "n_index:  5\n",
            "fold_index:  9\n",
            "eval_index:  3\n",
            "error_type:  number_of_arms\n",
            "n_index:  5\n",
            "fold_index:  9\n",
            "eval_index:  4\n",
            "ğŸ© https://wandb.ai/srws-psg/arm_matching_GPT4o/r/call/c81c957b-936f-49fa-a4df-b495a2c5cc39\n"
          ]
        }
      ],
      "source": [
        "#Specify the path where the extracted data were stored\n",
        "extracted_data_dir = \"extracted_data_log_GPT_v8\"\n",
        "\n",
        "#Specify developed description obtained by which method is used\n",
        "shot_name = \"chat\"\n",
        "for n_index in range(5,6):\n",
        "  for fold_index in range(10):\n",
        "    for eval_index in range(5):\n",
        "      print(\"n_index: \", n_index)\n",
        "      print(\"fold_index: \", fold_index)\n",
        "      print(\"eval_index: \", eval_index)\n",
        "\n",
        "      # Create a new row with specified columns\n",
        "      new_row = pd.DataFrame(columns=columns)\n",
        "      new_row.loc[0] = {col: \"\" for col in columns}\n",
        "      new_row.loc[0, \"n_index\"] = n_index\n",
        "      new_row.loc[0, \"fold_index\"] = fold_index\n",
        "      new_row.loc[0, \"eval_index\"] = eval_index\n",
        "\n",
        "      try:\n",
        "        # Construct the path to the extracted data JSON file\n",
        "        extracted_data_path = os.path.join(extracted_data_dir, f\"{shot_name}/{n_index}_paper/{fold_index}_fold/extracted_data_{eval_index}.json\")\n",
        "        with open(extracted_data_path, 'r', encoding='utf-8') as file:\n",
        "          # Load the JSON file\n",
        "          extracted_data = json.load(file)\n",
        "\n",
        "      except Exception as e:\n",
        "        file_name = \"extracted_data_loading\"\n",
        "        new_row.loc[0, \"error\"] = f\"{file_name}: {str(e)}\"\n",
        "        df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
        "        print(\"error_type: \", file_name)\n",
        "        continue;\n",
        "\n",
        "      # Extract the paper name from the keys of the extracted data\n",
        "      paper_name = list(extracted_data.keys())[0]\n",
        "      new_row.loc[0, \"paper_name\"] = paper_name\n",
        "\n",
        "      # Get the list of arm names from the extracted data\n",
        "      GPT_arms_list = list(extracted_data[paper_name].keys())\n",
        "\n",
        "      try:\n",
        "        # Retrieve the human-provided list of arm names for the paper\n",
        "        human_arms_list = study_dict[paper_name]\n",
        "      except Exception as e:\n",
        "        file_name = \"no_paper_name\"\n",
        "        new_row.loc[0, \"error\"] = f\"{file_name}: {str(e)}\"\n",
        "        df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
        "        print(\"error_type: \", file_name)\n",
        "        continue;\n",
        "\n",
        "      # Store the arm names extracted by GPT and human in the new row\n",
        "      for i in range(len(GPT_arms_list)):\n",
        "          new_row.loc[0, f\"GPT_{i+1}\"] = GPT_arms_list[i]\n",
        "      for i in range(len(human_arms_list)):\n",
        "          new_row.loc[0, f\"human_{i+1}\"] = human_arms_list[i]\n",
        "\n",
        "      # Check if the number of arms match between GPT and human data\n",
        "      if len(GPT_arms_list) != len(human_arms_list):\n",
        "        file_name = \"number_of_arms\"\n",
        "        e = \"The numbers of the arms in both lists are not matched.\\n\\n\"\n",
        "        new_row.loc[0, \"error\"] = f\"{file_name}: {str(e)}\"\n",
        "        df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
        "        print(\"error_type: \", file_name)\n",
        "        continue;\n",
        "\n",
        "      # Create tools for word matching\n",
        "      try:\n",
        "        tools = make_tools(GPT_arms_list)\n",
        "      except Exception as e:\n",
        "        file_name = \"making_tools\"\n",
        "        new_row.loc[0, \"error\"] = f\"{file_name}: {str(e)}\"\n",
        "        df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
        "        print(\"error_type: \", file_name)\n",
        "        continue;\n",
        "\n",
        "      # Prepare messages for GPT function calling\n",
        "      messages=[]\n",
        "      system_content = \"Use the word_matching tool in your response.\"\n",
        "      user_content = \"\"\"You have to answer the most matched word for each name in the word_matching tool.\n",
        "      Use the word_matching tool in your response.\n",
        "      Below is a word list from which you can choose and answer.\\n\n",
        "      \"\"\"\n",
        "\n",
        "      for arms_list_num in range(len(human_arms_list)):\n",
        "        user_content += human_arms_list[arms_list_num]\n",
        "        user_content += \"\\n\"\n",
        "\n",
        "      messages.append({\"role\": \"system\", \"content\": system_content})\n",
        "      messages.append({\"role\": \"user\", \"content\": user_content})\n",
        "\n",
        "      # Call GPT function for word matching\n",
        "      try:\n",
        "        response = GPT_function_calling(tools, messages, \"word_matching\")\n",
        "\n",
        "      except Exception as e:\n",
        "        file_name = \"GPT_chat\"\n",
        "        new_row.loc[0, \"error\"] = f\"{file_name}: {str(e)}\"\n",
        "        df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
        "        print(\"error_type: \", file_name)\n",
        "        continue;\n",
        "\n",
        "      # Process the response from GPT function calling\n",
        "      try:\n",
        "        tools_data= json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
        "        # Store the tools data in the new row\n",
        "        i = 0\n",
        "        for key, value in tools_data.items():\n",
        "            if i < 5:  # Store up to 5 key-value pairs\n",
        "                new_row.loc[0, f\"key_{i+1}\"] = key\n",
        "                new_row.loc[0, f\"value_{i+1}\"] = value\n",
        "                new_row.loc[0, f\"key_{i+1}_matched\"] = \"\"\n",
        "                new_row.loc[0, f\"value_{i+1}_matched\"] = \"\"\n",
        "            i += 1\n",
        "        df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
        "\n",
        "      except Exception as e:\n",
        "        file_name = \"output_loading\"\n",
        "        new_row.loc[0, \"error\"] = f\"{file_name}: {str(e)}\"\n",
        "        df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
        "        print(\"error_type: \", file_name)\n",
        "        continue;\n",
        "\n",
        "# Output the DataFrame to an Excel file\n",
        "excel_path_updated = \"arm_matched_list.xlsx\"\n",
        "df_output.to_excel(excel_path_updated, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMNDETglY7csXlhtR1d0wB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}